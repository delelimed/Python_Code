{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "posso sommare array con stesse dimensioni o differenti\n",
    "posso fare operazioni tra vettori (@ è prodotto vettoriale). \n",
    "\n",
    "posso trasformare array. \n",
    "se voglio trasformare array con shape 6,2,2 , parto da più interna e raggruppo più elementi\n",
    "111 112 113 115 121 122 124 135 131 132 133 134 (fai esempio)\n",
    "\n",
    "operazioni con array senza dimensioni uguali: cercano di fare in modo che le dimensioni siano compatibili, fa broadcasting, paragona dimensioni partendo da dx, sia in numpy che pytorch. \n",
    "plottaggi con matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFORMATION THEORY \n",
    "## Misurare la distanza tra due funzioni di probabilità\n",
    "\n",
    "Concetto importante è INFORMATION CONTENT (contenuto informativo di una distribuzione di probabilità): consideriamo due eventi \"Domani sorge il sole\", \"alla prossima lotteria usciranno i numeri 3 2 5 9 8\". Il secondo evento ha un maggior contenuto informativo, è meno probabile. \n",
    "I(x) = -log(p(x)) , ha senso con definizione perchè p(x) sta tra 0 ed 1, il logaritmo è una curva decrescente. \n",
    "Entropia di distribuzione è il valore atteso del contenuto informativo. \n",
    "H(p(x)) = E[I(x)] = sum_x(-p(x)log(p(x)))\n",
    "\n",
    "Possiamo andare a calcolare entropia di due distribuzioni diverse:\n",
    "graph \n",
    "\n",
    "entropia può dare interpretazione diversa, se devo mandare 4 simboli, uno di questi con probabilità molto maggiore, posso usare la funzione\n",
    "x = -log_2(p(x)) per calcolare il numero di bit da usare per minimizzare il costo della comunicazione. \n",
    "\n",
    "H_p(q) = sum_x(q(x)log_2(p(x))), mi dice quanto costa in media mandare un messaggio per una distribuzione (q) ma usano dun altro encoding(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funzioni di Loss\n",
    "\n",
    "## Maximum Likelihood Estimation\n",
    "\n",
    "O_ml = (argmax/theta) P_model (x; theta)\n",
    "Consideriamo il problema di classificazione.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
